============ 任性的分割线 ===============
## 埋点采集的常见方式方法

**1. 服务端访问日志**

- 优点：最简单的访问日志数据，无需刻意埋点，数据天然生成。

- 缺点：只能采集接口的访问信息，且本身不是为统计行为而生的，会掺杂错误日志信息、冗余的数据且数据结构不契合，甚至一些需要统计的数据并不能获得。

**2. 前端页面手工埋点上报**

- 优点：最常见的手工埋点体系，可采集任意指定的交互事件或业务事件，也可以采集到有深度的接口数据。

- 缺点：代码侵入性强，随着埋点数量的增加后期变得不易维护，如果用来采集交互行为的话会比较痛苦。

**3. 可视化埋点**

- 优点： 开发人员参与度低，产品或运营可以直接在系统界面上傻瓜化完成埋点工作，交互友好

- 缺点：搭建实现成本较高，版本协同成本也比较高，如某个版本将某按钮移除或修改了页面结构、交互方式等，需要较强的开发规范约束。可采集的数据也较浅

**4. “无埋点”**

- 优点：接入友好，无需代码入侵，极大程度避免了因需求变更、埋点错误等原因导致的重新埋点繁复工作。

- 缺点：本质上是全量采集后再定向筛选，所以采集的数据量**巨大**，需要加入节流处理，其实也是把定向采集的工作量由前端转移到了产品。只能采集页面交互行为数据，无法采集有深度的接口数据

## 究竟什么是“无埋点”？

所谓无埋点，其实就是“全埋点”。是将页面上所以能够采集到的交互事件进行全量上报，然后再由产品配置对上报数据进行定向筛选，决定哪些数据需要入库分析。

在存储细节上，也可以选择保留未被筛选的数据，这样的好处在于数据可以回溯，如果上线若干天后发现遗漏或错选了需要统计的数据，只需更新筛选配置即可，而不会丢失前几天的上报数据，缺点是数据存量会特别大（这也是早期区分【无埋点】和【全埋点】的依据，现在这种边界已几乎消除）。

筛选配置方面，可以是“先配置，后埋点”，也可以是“先埋点，后筛选”，前者的理念变形一下就是可视化买埋点的基础。

无埋点可以基于 xpath，也可以基于事件抽象。

> xpath：分为精确路径和概略路径两种做法
> 精确路径：body>div[0]>div[3]>ul>li[5]>a[0] ，从被点击的元素不断向上查找到根节点，并记录过程中每个节点的。
> 概略路径：body>div.header>div.nav>a[23]，在前者的基础上省略上溯路径中非白名单中的节点

> 事件抽象：用户在网站上的所有操作都可以被抽象为事件（静止不动和页面失去焦点都是事件），上报的日志不再是定向的埋点结果，而是对所有发生的事件进行上报。在事件的模型中我们可以把事件分为：瞬发事件和持续事件
>
> 瞬发事件：例如常见的点击
>
> 持续事件：例如常见的页面滚动

## 我们的自动化埋点

### 无痕埋点与手工埋点双模式并行

从采集角度来看，数据属性可以分为“交互行为数据”和“业务逻辑数据”。

目前所流行的无论是“无痕埋点”还是“可视化埋点”，更多的还是在解决如何低成本获取“用户设备信息”和“交互行为数据”的问题。

如果某个埋点的触发需要放在回调函数里、需要聚合一个表单的填写值，或是需要一些前置条件进行触发，则还是不可避免的需要使用手工埋点的方式进行。

san-greal 的设计初衷是提供一套轻量的方便接入使用的自动化埋点采集工具。针对这两种类型的数据使用无痕埋点和手工埋点双模式并行的方案。

针对“用户的交互行为数据”，基本只需要通过添加配置即可自动化采集。

```js
{
  catchError: true, // 是否捕捉脚本错误，默认false
  exposure: {
    // 自动化曝光上报配置
    enable: true, // 开启自动曝光上报功能，默认不开启
    keep: true // 开启持续上报，目标元素每曝光一次就上报一次，默认false
  },
  autoTrackSinglePage: {
    // 单页应用自动PV上报
    enable: true
  },
  autoTrackPageStayTime: {
    // 路由（页面）停留时长上报
    enable: true,
    router: ['/click-report', '/detail/:id'] // 需要上报的路由地址配置，支持react-router动态路由写法
  },
  autoTrack: {
    // 全自动埋点
    enable: true,
    className: 'need-auto-track' // 全自动上报以组件为粒度，这里配置需要全自动上报的组件class，会自动上报该class name下符合条件的元素的交互事件，支持ant
  }
}
```

在实际的业务场景中我们很多时候并不需要真的全量采集所有页面所有组件的交互行为，所以在无痕上报的处理上，san-greal 是以组件为粒度进行采集的，只需为父级组件添加你在`autoTrack`属性中配置的 className，san-greal 就会帮你自动采集该组件下的全量交互行为。

目前可采集的交互行为包括 click 事件和 blur 事件，细节上除了上报具体的点击元素和交互行为外，还会上报该元素上的所有属性以及该元素的 xpath，支持 antd 组件。

而针对有一定深度的数据采集，也同样提供的手工埋点的能力。其中一种更为轻量化的手工埋点方式是直接在元素上添加埋点属性：

```html
<!-- 点击上报，属性值即为上报的事件名 -->
<a href="#" click-track="home_banner_click">点击click上报</a>
<!-- 除了简单的次数上报之外，也支持通过标准JSON上报带属性的埋点 -->
<a href="#" click-track={JSON.parse({eventName: 'eventName', customKey: 'customValue'})}>点击click上报</a>
<!-- 除了点击，还支持曝光事件 -->
<div class="black-box"
     exp-track="modal-exposure-event"
     keep-track
      >
  呀哈哈，我被发现啦！
</div>
```

这种方式除了侵入性较小之外，可以满足大部分的手工埋点需求，在书写和阅读时也符合书写组件属性的一贯方式。目前支持上报点击和曝光（即元素由不可见变为可见，无论该元素在可见前是否存在，也无论该元素在可见前以任何形式隐藏，包括被滚动条隐藏）事件。

[一些实现细节](http://git.caimi-inc.com/client/papaya-docs/issues/46#%E8%87%AA%E5%8A%A8%E5%8C%96%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF)

少部分深度较深的埋点需求，则需要使用手工埋点的方式进行上报

```js
import sanGreal from '@wac/san-greal'
...
sanGreal.send('xxx',{...})
```

### 数据模型

我们将触发埋点的行为都视作一个“事件”，上报的数据格式使用了神策的 Event Model

简单来说，一个 Event 就是描述了：一个用户在某个时间点、某个地方，以某种方式完成了某个具体的事情。

```json
{
  "distinct_id": "2b0a6f51a3cd6775",
  "time": 1557659757582,
  "type": "track",
  "event": "PageView",
  "properties": {
    "$ip": "0.0.0.0",
    "user_gent": "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.）",
    "page_name": "网站首页",
    "url": "www.wacai.com",
    "referer": "www.baidu.com"
  }
}
```

## 只是工具 - 数据驱动开发帮助业务成长

无论是哪种埋点采集方式，最终都需要服务与业务，让数据驱动开发来帮助业务成长。

所以我们在采集具体的埋点数据之前，先应该根据需求梳理分析的指标和维度，然后再从指标和维度倒推需要在每个 Event 记录的字段。

<img src="http://git.caimi-inc.com/client/papaya-blog/uploads/d7e53a059ecd319a5585ef9f7bd4070a/fehelper-sensordata-wacai-info-dashboard-1557714274064.png" width="680">

以催收系统的埋点为例，业务希望通过新的 dashboard 页面来引导用户逐步放弃使用老的“待我处理”页面，希望用户能在 dashboard 页面上更高效的进行工作。

为了统计 dashboard 页面上线后是否达到预期的效果，我们就需要统计用户在 dashboard 页面点击案件到详情的转化率（由于将 dashboard 设为了系统默认的进入页面，所以该页面的 PV 数据并不能说明问题），以及待我处理页面的 PV 数据，和从待我处理到详情页之间的转化率。

宏观上，通过长期对这些数据的观察，即可得新功能是否达到预期效果，或离预期还有多少距离。

微观上，我们以“催收员”为维度查看 dashboard 页面的使用率，发现新加入的催收员使用 dashboard 页面的频率要明显高于老员工，那么就可以考虑是否是用户使用惯性的问题，那么就可以向用户加强这方面的宣导来改进。

数据后台提供了一些分析指标的方法可供参考：

- 事件分析
  - 普通的面向事件的分析工具，可以根据自定义属性，查看任意事件在一定事件内的触发总次数、触发人均数、触发人数或某属性的去重数
  - 也提供自定义指标分析，可以自定义公式统计指标，如 A 事件的总次数/B 事件的总次数得出的百分比指数
  - <img src="http://git.caimi-inc.com/client/papaya-blog/uploads/7afcd7077b4db06d2627ec579a67950c/image.png" width="680">
- 漏斗分析
  - 用于分析面向用户的事件转化率，统计一定时间内用户由 A 事件至 B 事件再至任意事件的转化率，以用户数为单位，单个用户不重复统计
  - <img src="http://git.caimi-inc.com/client/papaya-blog/uploads/64bd1ef8d53ccee649ac473246f2e531/image.png" width="680">
- 留存分析
  - 新用户留存分析，中后台系统无需关心
- 分布分析
  - 用于统计在一定时间内任意事件被触发的次数、小时数或其他属性去重数的分布情况，如用户触发 A 事件的次数分布情况，0-10 次，10-20 次...
  - <img src="http://git.caimi-inc.com/client/papaya-blog/uploads/8d30c148905d00da6208d018ea1626f7/image.png" width="680">
- 用户路径分析
  - 用于分析以某个事件为起始或结束，用户流量在一定时间内在若干指定事件内的事件触发路径，如以访问 dashbord 为起始，用户流量在各个其他页面访问的路径分布
  - 实际情况中一般用于统计以次数为维度的转化率，和漏斗分析作用类似但统计维度不同
  - <img src="http://git.caimi-inc.com/client/papaya-blog/uploads/b2ef2d4b32dfc154ea9b0ad4e6565ac5/image.png" width="680">
- 间隔分析
  - 用于统计用户在若干任意事件上的触发间隔事件，如从触发 A 事件到触发 B 事件，最少用了多久，最长多久，中位数是多少等
  - <img src="http://git.caimi-inc.com/client/papaya-blog/uploads/8c386233e07a628b2c6f943a862fb841/image.png" width="680">

在选择图表时，数据类型直接决定所要表达的图表类型，一般情况下想要表现离散数据选择柱状图，想要展现连续数据、表现数据的变化趋势选择折线图，想要表现地区数据则会选择地图作为数据展现的底图相应选择地图色彩图或地图气泡图等。

在梳理埋点需求时也需要依照一定的准则，1688UED 团队提到过 5 度用户体验质量模型，即从用户和产品“当前”关系的触达、行动、感知三个过程和“长远”阶段的回访、传播两个过程，定义数据指标分别是吸引度、完成度、满意度、忠诚度和推荐度。在中后台应用中会有稍许变化，但在“行动、感知和长远”三点来说是有参考意义的

> 行动–完成度：用户寻找自己感兴趣的内容（对应中后台的话应该是感兴趣的方式）进行相关操作，相应的完成度是衡量用户能否完成相应操作及完成相应操作的实际效率如何
>
> 感知–满意度：操作完成后对产品形成的主观感受，相应的满意度是指完成相应操作之后用户的满意程度及其他主观感受
>
> 回访和传播对应的忠诚度和推荐度指的是用户会不会再次使用该方式或将该方式推荐传播给其他人

## 埋点体系的未来展望

### 加入服务端埋点，将交互行为与请求行为分离

前端埋点采集的方式有其固有的缺陷，受网络环境和客户端、脚本稳定性影响，有时并不能保证数据的准确性。且在采集一些深度数据时，要么需要侵入代码手工埋点，要么一些后端处理的数据干脆就采集不到。

理想的情况是由前端来采集用户设备信息和用户交互行为数据，而由服务端采集业务交互数据，一来可以减少前端埋点代码的入侵，二来可以保证数据的准确性。

### 交互行为热力图

全埋点采集的一个好处就是可以生成页面点击如力图，如果加上一些持续性事件，或许可以有更多想象空间

<img src="http://git.caimi-inc.com/client/papaya-blog/uploads/4e54e0a722bd31a412e457995d3a9340/image.png" width="500">

### 基于本地存储和客户端分析的全量日志

全埋点采集的一个缺点就是采集数据巨大，而且其中大部分的数据实际上都用不到。而随着前端技术和计算机硬件的发展，前端逐渐具备了本地存储大量数据的能力，浏览器也能够使用更多的系统资源，以 localStorage、sessionStorage、indexDB 作为存储媒介，在本地 worker 中进行数据的初筛，甚至根据配置直接对数据进行算法分析过滤再上报，也成为一种可以考虑的方案。

### 解决单个用户的体验问题，真的需要海量用户的参照吗？

在实际和催收、电销系统用户的交谈和观察中发现，每个用户的工作内容虽然相同，但对工作方式的喜好并不一样。假设每种方式的工作效率相同，那么有没有可能让每个用户都能更好的在自己喜欢的方式下工作？

千人千面的概念听了很多，最广泛的体验还是在内容层面：采集当前用户对某些内容类型的偏好，丢给算法模型，再由智能推荐算法推送给用户他们更感兴趣的内容。

同样是采集 -> 分析 -> 定制化的路子，在解决单个用户的体验问题上或许也可以千人千面
